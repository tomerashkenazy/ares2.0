[2025-11-24 10:56:59 ARES 2.0] INFO: Runtime distributed=False, world_size=1, rank=0, local_rank=0, device_id=0
[2025-11-24 10:56:59 ARES 2.0] INFO: Experiment: convnext_small_linf_5.0_gradnorm_5.0_init1
[2025-11-24 10:56:59 ARES 2.0] INFO: Results directory: /home/ashtomer/projects/ares/results/convnext_small_linf_5.0_gradnorm_5.0_init1
[2025-11-24 10:56:59 ARES 2.0] INFO: Creating model: convnext_small
[2025-11-24 10:56:59 ARES 2.0] INFO: Model convnext_small created, param count:50223688
[2025-11-24 10:56:59 ARES 2.0] INFO: Using native Torch AMP. Training in mixed precision.
[2025-11-24 10:57:07 ARES 2.0] INFO: Experiment directory: /home/ashtomer/projects/ares/results/convnext_small_linf_5.0_gradnorm_5.0_init1
[2025-11-24 10:57:07 ARES 2.0] INFO: Experiment directory: /home/ashtomer/projects/ares/results/convnext_small_linf_5.0_gradnorm_5.0_init1
[2025-11-24 10:57:09 ARES 2.0] INFO: Weights & Biases logging initialized for run: None in group: test_models
[2025-11-24 10:57:09 ARES 2.0] INFO: Weights & Biases logging initialized for run: None in group: test_models
[2025-11-24 10:57:09 ARES 2.0] INFO: Start training for 250 epochs
[2025-11-24 10:57:09 ARES 2.0] INFO: Start training for 250 epochs
[2025-11-24 10:57:09 ARES 2.0] INFO: gradclip: None
[2025-11-24 10:57:09 ARES 2.0] INFO: gradclip: None
[2025-11-24 10:57:40 ARES 2.0] INFO: Train: [0/250] [   0/7 (  0%)]  Loss: 7.042 (7.04)  Time: 30.870s,    8.29/s  (30.870s,    8.29/s)  LR: 1.000e-06  Data: 2.702 (2.702)
[2025-11-24 10:57:40 ARES 2.0] INFO: Train: [0/250] [   0/7 (  0%)]  Loss: 7.042 (7.04)  Time: 30.870s,    8.29/s  (30.870s,    8.29/s)  LR: 1.000e-06  Data: 2.702 (2.702)
[2025-11-24 11:01:40 ARES 2.0] INFO: Runtime distributed=False, world_size=1, rank=0, local_rank=0, device_id=0
[2025-11-24 11:01:40 ARES 2.0] INFO: Experiment: convnext_small_linf_5.0_gradnorm_5.0_init1
[2025-11-24 11:01:41 ARES 2.0] INFO: Results directory: /home/ashtomer/projects/ares/results/convnext_small_linf_5.0_gradnorm_5.0_init1
[2025-11-24 11:01:41 ARES 2.0] INFO: Creating model: convnext_small
[2025-11-24 11:01:41 ARES 2.0] INFO: Model convnext_small created, param count:50223688
[2025-11-24 11:01:41 ARES 2.0] INFO: Using native Torch AMP. Training in mixed precision.
[2025-11-24 11:01:53 ARES 2.0] INFO: Experiment directory: /home/ashtomer/projects/ares/results/convnext_small_linf_5.0_gradnorm_5.0_init1
[2025-11-24 11:01:53 ARES 2.0] INFO: Experiment directory: /home/ashtomer/projects/ares/results/convnext_small_linf_5.0_gradnorm_5.0_init1
[2025-11-24 11:01:55 ARES 2.0] INFO: Weights & Biases logging initialized for run: None in group: test_models
[2025-11-24 11:01:55 ARES 2.0] INFO: Weights & Biases logging initialized for run: None in group: test_models
[2025-11-24 11:01:55 ARES 2.0] INFO: Start training for 250 epochs
[2025-11-24 11:01:55 ARES 2.0] INFO: Start training for 250 epochs
[2025-11-24 11:01:55 ARES 2.0] INFO: gradclip: None
[2025-11-24 11:01:55 ARES 2.0] INFO: gradclip: None
[2025-11-24 11:15:44 ARES 2.0] INFO: Runtime distributed=False, world_size=1, rank=0, local_rank=0, device_id=0
[2025-11-24 11:15:44 ARES 2.0] INFO: Experiment: convnext_small_linf_5.0_gradnorm_5.0_init1
[2025-11-24 11:15:44 ARES 2.0] INFO: Results directory: /home/ashtomer/projects/ares/results/convnext_small_linf_5.0_gradnorm_5.0_init1
[2025-11-24 11:15:44 ARES 2.0] INFO: Creating model: convnext_small
[2025-11-24 11:15:44 ARES 2.0] INFO: Model convnext_small created, param count:50223688
[2025-11-24 11:15:45 ARES 2.0] INFO: Using native Torch AMP. Training in mixed precision.
[2025-11-24 11:15:56 ARES 2.0] INFO: Experiment directory: /home/ashtomer/projects/ares/results/convnext_small_linf_5.0_gradnorm_5.0_init1
[2025-11-24 11:15:56 ARES 2.0] INFO: Experiment directory: /home/ashtomer/projects/ares/results/convnext_small_linf_5.0_gradnorm_5.0_init1
[2025-11-24 11:15:59 ARES 2.0] INFO: Weights & Biases logging initialized for run: None in group: test_models
[2025-11-24 11:15:59 ARES 2.0] INFO: Weights & Biases logging initialized for run: None in group: test_models
[2025-11-24 11:15:59 ARES 2.0] INFO: Start training for 250 epochs
[2025-11-24 11:15:59 ARES 2.0] INFO: Start training for 250 epochs
[2025-11-24 11:15:59 ARES 2.0] INFO: gradclip: None
[2025-11-24 11:15:59 ARES 2.0] INFO: gradclip: None
[2025-11-24 11:17:30 ARES 2.0] INFO: Runtime distributed=False, world_size=1, rank=0, local_rank=0, device_id=0
[2025-11-24 11:17:30 ARES 2.0] INFO: Experiment: convnext_small_linf_5.0_gradnorm_5.0_init1
[2025-11-24 11:17:30 ARES 2.0] INFO: Results directory: /home/ashtomer/projects/ares/results/convnext_small_linf_5.0_gradnorm_5.0_init1
[2025-11-24 11:17:30 ARES 2.0] INFO: Creating model: convnext_small
[2025-11-24 11:17:31 ARES 2.0] INFO: Model convnext_small created, param count:50223688
[2025-11-24 11:17:31 ARES 2.0] INFO: Using native Torch AMP. Training in mixed precision.
[2025-11-24 11:17:55 ARES 2.0] INFO: Experiment directory: /home/ashtomer/projects/ares/results/convnext_small_linf_5.0_gradnorm_5.0_init1
[2025-11-24 11:17:55 ARES 2.0] INFO: Experiment directory: /home/ashtomer/projects/ares/results/convnext_small_linf_5.0_gradnorm_5.0_init1
[2025-11-24 11:17:57 ARES 2.0] INFO: Weights & Biases logging initialized for run: None in group: test_models
[2025-11-24 11:17:57 ARES 2.0] INFO: Weights & Biases logging initialized for run: None in group: test_models
[2025-11-24 11:17:57 ARES 2.0] INFO: Start training for 250 epochs
[2025-11-24 11:17:57 ARES 2.0] INFO: Start training for 250 epochs
[2025-11-24 11:17:57 ARES 2.0] INFO: gradclip: None
[2025-11-24 11:17:57 ARES 2.0] INFO: gradclip: None
